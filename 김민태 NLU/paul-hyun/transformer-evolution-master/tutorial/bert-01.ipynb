{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8fbfd8eea8c47f48e1c2450c89f1f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56c558e517ad48cb9ecff4d93fc102ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_709d936a27f24720a6b2fe56f4182a5b",
              "IPY_MODEL_f179ccd4599d4204ab1583db1b4e7ad6"
            ]
          }
        },
        "56c558e517ad48cb9ecff4d93fc102ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "709d936a27f24720a6b2fe56f4182a5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d00629fd7a5241e8ac4249007cae006f",
            "_dom_classes": [],
            "description": "Loading",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 3724301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1039716,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eceb795f3d6544688ce06962769cb2e2"
          }
        },
        "f179ccd4599d4204ab1583db1b4e7ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e64f4c29b6c4349b641ca81958b2b93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28% 1039716/3724301 [01:05&lt;02:47, 15983.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_797c7c3846654add9bb5e2cf6beb3126"
          }
        },
        "d00629fd7a5241e8ac4249007cae006f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eceb795f3d6544688ce06962769cb2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e64f4c29b6c4349b641ca81958b2b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "797c7c3846654add9bb5e2cf6beb3126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "077bf070e3d84aa1aadb13a999172d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fbd0ba8eedf40d382a1df7c638c07a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f61dfccc85f14d87b14631d4ab46c7ea",
              "IPY_MODEL_38cbd1b0ba41438cb4200a5d21a5b28d"
            ]
          }
        },
        "4fbd0ba8eedf40d382a1df7c638c07a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f61dfccc85f14d87b14631d4ab46c7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fac11e4e54af473fbf9f7b40d7e17fce",
            "_dom_classes": [],
            "description": "Making",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 100001,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100001,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccbef01597344a90b5798723adc2978e"
          }
        },
        "38cbd1b0ba41438cb4200a5d21a5b28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ffecf54ef544bcfab8744c226e33714",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 100001/100001 [01:05&lt;00:00, 1538.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42e97022207348a6b71e70d87755f1ef"
          }
        },
        "fac11e4e54af473fbf9f7b40d7e17fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccbef01597344a90b5798723adc2978e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ffecf54ef544bcfab8744c226e33714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42e97022207348a6b71e70d87755f1ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCF6eWlQGjH5",
        "colab_type": "text"
      },
      "source": [
        "## BERT 구현 과정 (1/2)\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2020-01-02/bert-pretrain.png)\n",
        "\n",
        "BERT 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (2/3)](https://paul-hyun.github.io/transformer-02/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (3/3)](https://paul-hyun.github.io/transformer-03/)\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcKmueewQQbf",
        "colab_type": "text"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B9WSoPaG5va",
        "colab_type": "code",
        "outputId": "b86baa31-562d-4501-df09-0aae38bb4fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 4.4MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 5.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 5.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 6.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 6.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 6.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 6.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 6.6MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 6.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=88ea3b6a7dbf32dc34143f68b13f93a2f5d452136e7fd1c19bd581e31ffe5f11\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t57ZDrpQVPf",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다.\n",
        "\n",
        "학습관련 [데이터 및 결과 파일](https://drive.google.com/open?id=15XGr-L-W6DSoR5TbniPMJASPsA0IDTiN)을 참고 하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo3kfdTxM_dx",
        "colab_type": "code",
        "outputId": "bf7d484c-fd77-4cbf-c6de-2687fa336921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K0u3OtaQcCG",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqJFoQFbQfaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from random import random, randrange, randint, shuffle, choice\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuQJkP4FQ17R",
        "colab_type": "text"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw9syi7mQ4Wf",
        "colab_type": "code",
        "outputId": "a9b5c862-71d4-4a61-e180-b6a1cee9ad7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n",
            "kowiki.txt\n",
            "kowiki_gpt.json\n",
            "save_gpt_pretrain.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TEqHwEVQ7ch",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJk2o8ykRDNn",
        "colab_type": "code",
        "outputId": "60bffe31-2818-42f8-e4df-96427e052d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cepm-CRzQ-Jf",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Config\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az1JWouiRAgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUBr9IYkRH8v",
        "colab_type": "code",
        "outputId": "85492973-2a22-49cc-dbdb-8daf7fb12185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_enc_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_seg_type\": 2,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yavmvonqRL5g",
        "colab_type": "text"
      },
      "source": [
        "#### 6. Common Class\n",
        "공통으로 사용되는 Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY99m9lMRMy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "\n",
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rmgSjxPRPzK",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Encoder\n",
        "Encoder 입니다.\n",
        "\n",
        "표준 Transformer Encoder에서 BERT에서 추가된 정의한 segment embedding만 추가 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtfrgJ9ORcwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder layer \"\"\"\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        return ffn_outputs, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIrkxJ-SRrxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder \"\"\"\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
        "        self.pos_emb = nn.Embedding(self.config.n_enc_seq + 1, self.config.d_hidn)\n",
        "        self.seg_emb = nn.Embedding(self.config.n_seg_type, self.config.d_hidn)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)  + self.seg_emb(segments)\n",
        "\n",
        "        # (bs, n_enc_seq, n_enc_seq)\n",
        "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cexyfhsQSHwK",
        "colab_type": "text"
      },
      "source": [
        "#### 8. BERT\n",
        "BERT 입니다.\n",
        "\n",
        "Transformer Encoder를 실행 합니다.  \n",
        "이후 첫번째 토큰을 linear, tahn를 실행 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVOKzzvKSNjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" bert \"\"\"\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.encoder = Encoder(self.config)\n",
        "\n",
        "        self.linear = nn.Linear(config.d_hidn, config.d_hidn)\n",
        "        self.activation = torch.tanh\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        outputs, self_attn_probs = self.encoder(inputs, segments)\n",
        "        # (bs, d_hidn)\n",
        "        outputs_cls = outputs[:, 0].contiguous()\n",
        "        outputs_cls = self.linear(outputs_cls)\n",
        "        outputs_cls = self.activation(outputs_cls)\n",
        "        # (bs, n_enc_seq, n_enc_vocab), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, outputs_cls, self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM9YREyBSU-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" BERT pretrain \"\"\"\n",
        "class BERTPretrain(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BERT(self.config)\n",
        "        # classfier\n",
        "        self.projection_cls = nn.Linear(self.config.d_hidn, 2, bias=False)\n",
        "        # lm\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_enc_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.bert.encoder.enc_emb.weight\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        outputs, outputs_cls, attn_probs = self.bert(inputs, segments)\n",
        "        # (bs, 2)\n",
        "        logits_cls = self.projection_cls(outputs_cls)\n",
        "        # (bs, n_enc_seq, n_enc_vocab)\n",
        "        logits_lm = self.projection_lm(outputs)\n",
        "        # (bs, n_enc_vocab), (bs, n_enc_seq, n_enc_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return logits_cls, logits_lm, attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0411eNM9Sb1s",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Pretrain Data 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCjhydEqSc1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 마스크 생성 \"\"\"\n",
        "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
        "    cand_idx = []\n",
        "    for (i, token) in enumerate(tokens):\n",
        "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
        "            continue\n",
        "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
        "            cand_idx[-1].append(i)\n",
        "        else:\n",
        "            cand_idx.append([i])\n",
        "    shuffle(cand_idx)\n",
        "\n",
        "    mask_lms = []\n",
        "    for index_set in cand_idx:\n",
        "        if len(mask_lms) >= mask_cnt:\n",
        "            break\n",
        "        if len(mask_lms) + len(index_set) > mask_cnt:\n",
        "            continue\n",
        "        for index in index_set:\n",
        "            masked_token = None\n",
        "            if random() < 0.8: # 80% replace with [MASK]\n",
        "                masked_token = \"[MASK]\"\n",
        "            else:\n",
        "                if random() < 0.5: # 10% keep original\n",
        "                    masked_token = tokens[index]\n",
        "                else: # 10% random word\n",
        "                    masked_token = choice(vocab_list)\n",
        "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
        "            tokens[index] = masked_token\n",
        "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
        "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
        "    mask_label = [p[\"label\"] for p in mask_lms]\n",
        "\n",
        "    return tokens, mask_idx, mask_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dryud7_9Shvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 쵀대 길이 초과하는 토큰 자르기 \"\"\"\n",
        "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_seq:\n",
        "            break\n",
        "\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            del tokens_a[0]\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sCSQ0a6Sj-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" doc별 pretrain 데이터 생성 \"\"\"\n",
        "def create_pretrain_instances(docs, doc_idx, doc, n_seq, mask_prob, vocab_list):\n",
        "    # for CLS], [SEP], [SEP]\n",
        "    max_seq = n_seq - 3\n",
        "    tgt_seq = max_seq\n",
        "    \n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i]) # line\n",
        "        current_length += len(doc[i])\n",
        "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
        "            if 0 < len(current_chunk):\n",
        "                a_end = 1\n",
        "                if 1 < len(current_chunk):\n",
        "                    a_end = randrange(1, len(current_chunk))\n",
        "                tokens_a = []\n",
        "                for j in range(a_end):\n",
        "                    tokens_a.extend(current_chunk[j])\n",
        "                \n",
        "                tokens_b = []\n",
        "                if len(current_chunk) == 1 or random() < 0.5:\n",
        "                    is_next = 0\n",
        "                    tokens_b_len = tgt_seq - len(tokens_a)\n",
        "                    random_doc_idx = doc_idx\n",
        "                    while doc_idx == random_doc_idx:\n",
        "                        random_doc_idx = randrange(0, len(docs))\n",
        "                    random_doc = docs[random_doc_idx]\n",
        "\n",
        "                    random_start = randrange(0, len(random_doc))\n",
        "                    for j in range(random_start, len(random_doc)):\n",
        "                        tokens_b.extend(random_doc[j])\n",
        "                else:\n",
        "                    is_next = 1\n",
        "                    for j in range(a_end, len(current_chunk)):\n",
        "                        tokens_b.extend(current_chunk[j])\n",
        "\n",
        "                trim_tokens(tokens_a, tokens_b, max_seq)\n",
        "                assert 0 < len(tokens_a)\n",
        "                assert 0 < len(tokens_b)\n",
        "\n",
        "                tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
        "                segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "                tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
        "\n",
        "                instance = {\n",
        "                    \"tokens\": tokens,\n",
        "                    \"segment\": segment,\n",
        "                    \"is_next\": is_next,\n",
        "                    \"mask_idx\": mask_idx,\n",
        "                    \"mask_label\": mask_label\n",
        "                }\n",
        "                instances.append(instance)\n",
        "\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "    return instances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY-6jSDsSuvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터 생성 \"\"\"\n",
        "def make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob):\n",
        "    vocab_list = []\n",
        "    for id in range(vocab.get_piece_size()):\n",
        "        if not vocab.is_unknown(id):\n",
        "            vocab_list.append(vocab.id_to_piece(id))\n",
        "\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "    \n",
        "    docs = []\n",
        "    with open(in_file, \"r\") as f:\n",
        "        doc = []\n",
        "        with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "            for i, line in enumerate(f):\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if 0 < len(doc):\n",
        "                        docs.append(doc)\n",
        "                        doc = []\n",
        "                        # 메모리 사용량을 줄이기 위해 100,000개만 처리 함\n",
        "                        if 100000 < len(docs): break\n",
        "                else:\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "                pbar.update(1)\n",
        "        if doc:\n",
        "            docs.append(doc)\n",
        "\n",
        "    for index in range(count):\n",
        "        output = out_file.format(index)\n",
        "        if os.path.isfile(output): continue\n",
        "\n",
        "        with open(output, \"w\") as out_f:\n",
        "            with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\n",
        "                for i, doc in enumerate(docs):\n",
        "                    instances = create_pretrain_instances(docs, i, doc, n_seq, mask_prob, vocab_list)\n",
        "                    for instance in instances:\n",
        "                        out_f.write(json.dumps(instance))\n",
        "                        out_f.write(\"\\n\")\n",
        "                    pbar.update(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_ihvSolSzoT",
        "colab_type": "code",
        "outputId": "1e8a3aa7-820c-4c78-bf9a-f5cf1197dbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "b8fbfd8eea8c47f48e1c2450c89f1f02",
            "56c558e517ad48cb9ecff4d93fc102ea",
            "709d936a27f24720a6b2fe56f4182a5b",
            "f179ccd4599d4204ab1583db1b4e7ad6",
            "d00629fd7a5241e8ac4249007cae006f",
            "eceb795f3d6544688ce06962769cb2e2",
            "2e64f4c29b6c4349b641ca81958b2b93",
            "797c7c3846654add9bb5e2cf6beb3126",
            "077bf070e3d84aa1aadb13a999172d00",
            "4fbd0ba8eedf40d382a1df7c638c07a1",
            "f61dfccc85f14d87b14631d4ab46c7ea",
            "38cbd1b0ba41438cb4200a5d21a5b28d",
            "fac11e4e54af473fbf9f7b40d7e17fce",
            "ccbef01597344a90b5798723adc2978e",
            "7ffecf54ef544bcfab8744c226e33714",
            "42e97022207348a6b71e70d87755f1ef"
          ]
        }
      },
      "source": [
        "in_file = f\"{data_dir}/kowiki.txt\"\n",
        "out_file = f\"{data_dir}/kowiki_bert\" + \"_{}.json\"\n",
        "count = 1\n",
        "n_seq = 256\n",
        "mask_prob = 0.15\n",
        "\n",
        "make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8fbfd8eea8c47f48e1c2450c89f1f02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Loading', max=3724301, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "077bf070e3d84aa1aadb13a999172d00",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Making', max=100001, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WH8ygciLOsg",
        "colab_type": "text"
      },
      "source": [
        "#### 10. Pretrain Data\n",
        "GPT Pretrain Data 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYQy0jh7LPlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터셋 \"\"\"\n",
        "class PretrainDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels_cls = []\n",
        "        self.labels_lm = []\n",
        "        self.sentences = []\n",
        "        self.segments = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                instance = json.loads(line)\n",
        "                self.labels_cls.append(instance[\"is_next\"])\n",
        "                sentences = [vocab.piece_to_id(p) for p in instance[\"tokens\"]]\n",
        "                self.sentences.append(sentences)\n",
        "                self.segments.append(instance[\"segment\"])\n",
        "                mask_idx = np.array(instance[\"mask_idx\"], dtype=np.int)\n",
        "                mask_label = np.array([vocab.piece_to_id(p) for p in instance[\"mask_label\"]], dtype=np.int)\n",
        "                label_lm = np.full(len(sentences), dtype=np.int, fill_value=-1)\n",
        "                label_lm[mask_idx] = mask_label\n",
        "                self.labels_lm.append(label_lm)\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels_cls) == len(self.labels_lm)\n",
        "        assert len(self.labels_cls) == len(self.sentences)\n",
        "        assert len(self.labels_cls) == len(self.segments)\n",
        "        return len(self.labels_cls)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels_cls[item]),\n",
        "                torch.tensor(self.labels_lm[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor(self.segments[item]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPEpzcFmLZ-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain data collate_fn \"\"\"\n",
        "def pretrin_collate_fn(inputs):\n",
        "    labels_cls, labels_lm, inputs, segments = list(zip(*inputs))\n",
        "\n",
        "    labels_lm = torch.nn.utils.rnn.pad_sequence(labels_lm, batch_first=True, padding_value=-1)\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "    segments = torch.nn.utils.rnn.pad_sequence(segments, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels_cls, dim=0),\n",
        "        labels_lm,\n",
        "        inputs,\n",
        "        segments\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7wrvZVOLca8",
        "colab_type": "code",
        "outputId": "4090b0f3-f234-4ff5-f227-e5db3a121bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\" pretrain 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_bert_0.json\")\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/Data/transformer-evolution/kowiki_bert_0.json: 100%|██████████| 239857/239857 [01:14<00:00, 3224.46 lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yERFmhF-LmKM",
        "colab_type": "text"
      },
      "source": [
        "#### 11. Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN9IHtGBLm5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels_cls, labels_lm, inputs, segments = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, segments)\n",
        "            logits_cls, logits_lm = outputs[0], outputs[1]\n",
        "\n",
        "            loss_cls = criterion_cls(logits_cls, labels_cls)\n",
        "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
        "            loss = loss_cls + loss_lm\n",
        "\n",
        "            loss_val = loss_lm.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFfDno62MCCb",
        "colab_type": "code",
        "outputId": "0d3c4523-0916-44fb-c928-595ac5b29e60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 20"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkofvdbFMEX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTPretrain(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_bert_pretrain.pth\"\n",
        "best_epoch, best_loss = 0, 0\n",
        "if os.path.isfile(save_pretrain):\n",
        "    best_epoch, best_loss = model.bert.load(save_pretrain)\n",
        "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
        "    best_epoch += 1\n",
        "\n",
        "model.to(config.device)\n",
        "\n",
        "criterion_lm = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
        "criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n",
        "offset = best_epoch\n",
        "for step in range(n_epoch):\n",
        "    epoch = step + offset\n",
        "    if 0 < step:\n",
        "        del train_loader\n",
        "        dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_bert_{epoch % count}.json\")\n",
        "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)\n",
        "\n",
        "    loss = train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader)\n",
        "    losses.append(loss)\n",
        "    model.bert.save(epoch, loss, save_pretrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FFSPSlQMn29",
        "colab_type": "code",
        "outputId": "34c02477-4241-4792-d187-efdccf22d9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        }
      },
      "source": [
        "# data\n",
        "data = {\n",
        "    \"loss\": losses\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses, label=\"loss\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.027608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.801137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.325305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.015369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.909906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.861085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.828222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6.804363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.788513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.774536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.762376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.751169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.742494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.736208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.727837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.724009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6.717879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>6.711692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.709890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>6.707203</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss\n",
              "0   18.027608\n",
              "1    8.801137\n",
              "2    7.325305\n",
              "3    7.015369\n",
              "4    6.909906\n",
              "5    6.861085\n",
              "6    6.828222\n",
              "7    6.804363\n",
              "8    6.788513\n",
              "9    6.774536\n",
              "10   6.762376\n",
              "11   6.751169\n",
              "12   6.742494\n",
              "13   6.736208\n",
              "14   6.727837\n",
              "15   6.724009\n",
              "16   6.717879\n",
              "17   6.711692\n",
              "18   6.709890\n",
              "19   6.707203"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAEGCAYAAACeiKhrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACAAgjNAAAAQAH/Df+XECQRmdb4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}