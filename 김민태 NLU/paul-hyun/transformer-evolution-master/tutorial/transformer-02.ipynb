{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer-02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq4StkI_HpXa",
        "colab_type": "text"
      },
      "source": [
        "## Transformer 구현 과정 (2/2)\n",
        "\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/transformer-model-architecture.png)\n",
        "\n",
        "Transformer 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQGy_iXGIAfi",
        "colab_type": "text"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvCrh7LAHSMi",
        "colab_type": "code",
        "outputId": "a589d257-d0c9-4021-9b6f-c880f742c252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=80b2a24dcc94b92e437a15edee190ba750ba2b9a8c5447fae1e6def9ed2ff408\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJEj4JnOIHdp",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다.\n",
        "\n",
        "학습관련 [데이터 및 결과 파일](https://drive.google.com/open?id=15XGr-L-W6DSoR5TbniPMJASPsA0IDTiN)을 참고 하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu_muOIjILVC",
        "colab_type": "code",
        "outputId": "40f8dcf7-b38b-4df9-998e-9acf5c6e177f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ATUwUJlIU86",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dquM-bfUIW-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj8iGv_HIbQp",
        "colab_type": "text"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pjohaiGId95",
        "colab_type": "code",
        "outputId": "7e5d8ddc-d2f3-4059-b53b-d1d1304aa746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOhCFxLPIdWx",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다.\n",
        "\n",
        "로딩된 vocab을 이용해 input을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u69gqsv_IkrL",
        "colab_type": "code",
        "outputId": "3609e01b-9c36-4009-9e0d-d5d9ac0a7e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12ZA0bI6Ip4s",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Config\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHGknKGNI9SU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3UQU0e8JM0b",
        "colab_type": "code",
        "outputId": "202d1af5-c2c5-421f-bb0c-fc6ba16320eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_enc_vocab\": len(vocab),\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_dec_seq\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_dec_vocab': 8007, 'n_enc_seq': 256, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3ZAB1PjJv9e",
        "colab_type": "text"
      },
      "source": [
        "#### 6. Common Class\n",
        "이전에 설명된 공통으로 사용되는 Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwm_ftQhKHJV",
        "colab_type": "text"
      },
      "source": [
        "###### get_sinusoid_encoding_table\n",
        "Positional Encoding 값을 구하기 위한 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWTOw-L8KAV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJRbra2GKjZx",
        "colab_type": "text"
      },
      "source": [
        "###### get_attn_pad_mask\n",
        "Padding Mask를 구하기 위한 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNN6p8r6KhzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJbvIXsNjloN",
        "colab_type": "text"
      },
      "source": [
        "###### get_attn_decoder_mask\n",
        "Decoder Mask를 구하기 위한 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SegQU2N5jmR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7rndBaMj16n",
        "colab_type": "text"
      },
      "source": [
        "###### ScaledDotProductAttention\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/scale_dot_product_attention.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byTcmFiLj2ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJMLVMjkj7_1",
        "colab_type": "text"
      },
      "source": [
        "###### MultiHeadAttention\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/multi_head_attention.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCDPmr4sj8hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df1dKmZSkEiV",
        "colab_type": "text"
      },
      "source": [
        "###### PoswiseFeedForwardNet\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/feed-forward.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDahw_QvkE6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQaP14UDkgpV",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Encoder\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/encoder.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HxrA0mdkoFu",
        "colab_type": "text"
      },
      "source": [
        "###### EncoderLayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My0FZFqFkns1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder layer \"\"\"\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        return ffn_outputs, attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OqU2L7IlDO_",
        "colab_type": "text"
      },
      "source": [
        "###### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuRgl12Ekg9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder \"\"\"\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_enc_seq, n_enc_seq)\n",
        "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYxaY_hYlYcv",
        "colab_type": "text"
      },
      "source": [
        "#### 8. Decoder\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-19/decoder.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Fw0xtJlcyC",
        "colab_type": "text"
      },
      "source": [
        "###### DecoderLayer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaQlf1uElb_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder layer \"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.dec_enc_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
        "        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVw019y4lkxM",
        "colab_type": "text"
      },
      "source": [
        "###### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d7mwC7clnG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder \"\"\"\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "    \n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "        # (bs, n_dec_seq, n_enc_seq)\n",
        "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n",
        "\n",
        "        self_attn_probs, dec_enc_attn_probs = [], []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n",
        "            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "            dec_enc_attn_probs.append(dec_enc_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n",
        "        return dec_outputs, self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YevWC1osltnH",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvs28anxl3UX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" transformer \"\"\"\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.encoder = Encoder(self.config)\n",
        "        self.decoder = Decoder(self.config)\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fW_lLz_zONS",
        "colab_type": "text"
      },
      "source": [
        "#### 10. Naver 영화 분류 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xM6W55dzPrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" naver movie classfication \"\"\"\n",
        "class MovieClassification(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = Transformer(self.config)\n",
        "        self.projection = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.transformer(enc_inputs, dec_inputs)\n",
        "        # (bs, d_hidn)\n",
        "        dec_outputs, _ = torch.max(dec_outputs, dim=1)\n",
        "        # (bs, n_output)\n",
        "        logits = self.projection(dec_outputs)\n",
        "        # (bs, n_output), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDx-7ZE-0C64",
        "colab_type": "text"
      },
      "source": [
        "#### 11. 네이버 영화 분류 데이터\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hRUATPWRo1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 영화 분류 데이터셋 \"\"\"\n",
        "class MovieDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                data = json.loads(line)\n",
        "                self.labels.append(data[\"label\"])\n",
        "                self.sentences.append([vocab.piece_to_id(p) for p in data[\"doc\"]])\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.sentences)\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor([self.vocab.piece_to_id(\"[BOS]\")]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjDhfnnWR2hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" movie data collate_fn \"\"\"\n",
        "def movie_collate_fn(inputs):\n",
        "    labels, enc_inputs, dec_inputs = list(zip(*inputs))\n",
        "\n",
        "    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels, dim=0),\n",
        "        enc_inputs,\n",
        "        dec_inputs,\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIJqTZswR_Q5",
        "colab_type": "code",
        "outputId": "7a82edb4-54a5-4447-a0ff-32db6cf262a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\" 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "train_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_train.json\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
        "test_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_test.json\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/Data/transformer-evolution/ratings_train.json: 100%|██████████| 149995/149995 [00:03<00:00, 42890.29 lines/s]\n",
            "Loading /content/drive/My Drive/Data/transformer-evolution/ratings_test.json: 100%|██████████| 49997/49997 [00:01<00:00, 47199.38 lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI3VfPuVS6s8",
        "colab_type": "text"
      },
      "source": [
        "#### 11. 네이버 영화 분류 데이터 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LewCUJDHTJjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 평가 \"\"\"\n",
        "def eval_epoch(config, model, data_loader):\n",
        "    matchs = []\n",
        "    model.eval()\n",
        "\n",
        "    n_word_total = 0\n",
        "    n_correct_total = 0\n",
        "    with tqdm_notebook(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
        "        for i, value in enumerate(data_loader):\n",
        "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            outputs = model(enc_inputs, dec_inputs)\n",
        "            logits = outputs[0]\n",
        "            _, indices = logits.max(1)\n",
        "\n",
        "            match = torch.eq(indices, labels).detach()\n",
        "            matchs.extend(match.cpu())\n",
        "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
        "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc9AcaiYTKK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm_notebook(total=len(train_loader), desc=f\"Train {epoch}\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(enc_inputs, dec_inputs)\n",
        "            logits = outputs[0]\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            loss_val = loss.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62PrcR_qTs3G",
        "colab_type": "code",
        "outputId": "51788523-7911-4cdb-b186-52a1671adb41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config.n_output = 2\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_dec_vocab': 8007, 'n_enc_seq': 256, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda'), 'n_output': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mATLq-JjUAa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MovieClassification(config)\n",
        "model.to(config.device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "best_epoch, best_loss, best_score = 0, 0, 0\n",
        "losses, scores = [], []\n",
        "for epoch in range(n_epoch):\n",
        "    loss = train_epoch(config, epoch, model, criterion, optimizer, train_loader)\n",
        "    score = eval_epoch(config, model, test_loader)\n",
        "\n",
        "    losses.append(loss)\n",
        "    scores.append(score)\n",
        "\n",
        "    if best_score < score:\n",
        "        best_epoch, best_loss, best_score = epoch, loss, score\n",
        "print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0WVadcVJr58",
        "colab_type": "code",
        "outputId": "1cf071c0-9da3-4413-eb8c-62d68b116dea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "# table\n",
        "data = {\n",
        "    \"loss\": losses,\n",
        "    \"score\": scores\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses, label=\"loss\")\n",
        "plt.plot(scores, label=\"score\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.484429</td>\n",
              "      <td>0.802268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.403221</td>\n",
              "      <td>0.817009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.375795</td>\n",
              "      <td>0.812249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.355647</td>\n",
              "      <td>0.826450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.334026</td>\n",
              "      <td>0.829990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.313187</td>\n",
              "      <td>0.827850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.291726</td>\n",
              "      <td>0.834270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.268704</td>\n",
              "      <td>0.834070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.245113</td>\n",
              "      <td>0.834710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.220757</td>\n",
              "      <td>0.833990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss     score\n",
              "0  0.484429  0.802268\n",
              "1  0.403221  0.817009\n",
              "2  0.375795  0.812249\n",
              "3  0.355647  0.826450\n",
              "4  0.334026  0.829990\n",
              "5  0.313187  0.827850\n",
              "6  0.291726  0.834270\n",
              "7  0.268704  0.834070\n",
              "8  0.245113  0.834710\n",
              "9  0.220757  0.833990"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAEGCAYAAABM2KIzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}