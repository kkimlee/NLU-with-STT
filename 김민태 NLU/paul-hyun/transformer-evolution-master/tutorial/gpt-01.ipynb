{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8dc295127c4f4a28a8a13b78022ce6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec7bc20677ba4441a629ec6af1d57e37",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_716a88c4f7e9498fb79c40794023b127",
              "IPY_MODEL_788a646aae6f498ab29f309f6d6c9f11"
            ]
          }
        },
        "ec7bc20677ba4441a629ec6af1d57e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "716a88c4f7e9498fb79c40794023b127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d88bf438f4c84fb7b2e6f4335eb80ba9",
            "_dom_classes": [],
            "description": "Loading",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 3724301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1039716,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af03fa62ebce434398b7c3e38f72c127"
          }
        },
        "788a646aae6f498ab29f309f6d6c9f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8bf86c7730f4d13931b4d3fb7804920",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28% 1039716/3724301 [01:01&lt;02:39, 16808.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a232a1d965049d7b619890f0dbd79a5"
          }
        },
        "d88bf438f4c84fb7b2e6f4335eb80ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af03fa62ebce434398b7c3e38f72c127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8bf86c7730f4d13931b4d3fb7804920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a232a1d965049d7b619890f0dbd79a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b1caee6eaa94486832d3963b265fa50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6e9015a0b90484f8d911d9e4cf84cf0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ece11f61476040ab9d2b17d27bc58c3e",
              "IPY_MODEL_398891195001409fa4c543afeec5a82e"
            ]
          }
        },
        "f6e9015a0b90484f8d911d9e4cf84cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ece11f61476040ab9d2b17d27bc58c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8830e63a63e4eef8d4f029a70e17b0a",
            "_dom_classes": [],
            "description": "Making",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 100001,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100001,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e5c7eb7c27546fab9bad2b799da7592"
          }
        },
        "398891195001409fa4c543afeec5a82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c30720aa36d04543817755e2952ded0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 100001/100001 [00:09&lt;00:00, 10180.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c03a6bc3c194ec085ae3164480ac50a"
          }
        },
        "b8830e63a63e4eef8d4f029a70e17b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e5c7eb7c27546fab9bad2b799da7592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c30720aa36d04543817755e2952ded0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c03a6bc3c194ec085ae3164480ac50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "684d0bd53da8464585ca2718153c7116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dfbee92b558f46368b5021ac09ff2ae2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a23522159434afbae95dff95a2642e7",
              "IPY_MODEL_c745fe33b1974f22ad88c3d89e601311"
            ]
          }
        },
        "dfbee92b558f46368b5021ac09ff2ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a23522159434afbae95dff95a2642e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a4939f594ece433cba487426e4f91597",
            "_dom_classes": [],
            "description": "Loading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 239311,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 239311,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46e7639230f24233a4c49719844fdd8f"
          }
        },
        "c745fe33b1974f22ad88c3d89e601311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b3f56d392b2436c857c49d10984e040",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 239311/239311 [00:37&lt;00:00, 6449.43it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0195a06afe464ff7868ea718edb40c1b"
          }
        },
        "a4939f594ece433cba487426e4f91597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46e7639230f24233a4c49719844fdd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b3f56d392b2436c857c49d10984e040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0195a06afe464ff7868ea718edb40c1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ2K8q2ZNdYi",
        "colab_type": "text"
      },
      "source": [
        "## GPT 구현 과정 (1/2)\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-30/gpt-model-downstream.png)\n",
        "\n",
        "GPT 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (2/3)](https://paul-hyun.github.io/transformer-02/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (3/3)](https://paul-hyun.github.io/transformer-03/)\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zv4p31pOrXz",
        "colab_type": "text"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCKOY324MSV6",
        "colab_type": "code",
        "outputId": "9db192e0-9b70-4644-9916-bd8b00031734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 3.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 2.6MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=c88f24784a61a55cdb8465a6653d8063a394b9f6e13926c5c674e6fecd36e39d\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Hd8czWOuVp",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다.\n",
        "\n",
        "학습관련 [데이터 및 결과 파일](https://drive.google.com/open?id=15XGr-L-W6DSoR5TbniPMJASPsA0IDTiN)을 참고 하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2ky6cLBOy3M",
        "colab_type": "code",
        "outputId": "a1955fdf-e349-4653-d63e-3434fb90eb7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8hPeW5UO2HS",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5itaeWPKO4sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P-sul-UO9Di",
        "colab_type": "text"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-a1cEx9PCdS",
        "colab_type": "code",
        "outputId": "c4877602-5ac6-47d0-bcda-d9b741d0ab61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n",
            "kowiki.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr6iDLT2PB2E",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다.\n",
        "\n",
        "로딩된 vocab을 이용해 input을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DaQJYaaPG7T",
        "colab_type": "code",
        "outputId": "ce210a0c-f4ca-4fdd-b912-70264b8b7668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-RlS2ETPMUU",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Config\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az2PFmXsPL_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx_KH9T8PSXi",
        "colab_type": "code",
        "outputId": "37888b35-0ccc-4e6f-a170-e4cc20d4e663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_dec_seq\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_dec_vocab': 8007, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAzEdbgfPbSE",
        "colab_type": "text"
      },
      "source": [
        "#### 6. Common Class\n",
        "공통으로 사용되는 Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkvv4pIYPZZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "\n",
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ogsZgK8Pt1O",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Decoder\n",
        "Decoder 입니다.\n",
        "\n",
        "표준 Transformer Decoder에서 Encoder를 사용하지 않기 때문에 Encoder-Decoder Mulit-Head Attention 부분을 제거 하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY6-NBmRP4nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder layer \"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, dec_inputs, self_attn_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(self_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(self_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQDo8rXNP-Uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder \"\"\"\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "    \n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "\n",
        "        self_attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq)\n",
        "            dec_outputs, self_attn_prob = layer(dec_outputs, dec_self_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, self_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSNTsw6ySFZ4",
        "colab_type": "text"
      },
      "source": [
        "#### 8. GPT\n",
        "GPT 입니다.\n",
        "\n",
        "단순히 Transformer Decoder를 실행 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voJ4vsHEQEfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" gpt \"\"\"\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.decoder = Decoder(self.config)\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.decoder(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, dec_self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4fveNyn3lGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" GPT pretrain \"\"\"\n",
        "class GPTPretrain(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.gpt = GPT(self.config)\n",
        "        # lm\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_dec_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.gpt.decoder.dec_emb.weight\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.gpt(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab)\n",
        "        logits_lm = self.projection_lm(dec_outputs)\n",
        "        # (bs, n_dec_seq - 1, n_dec_vocab), (bs, n_output), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return logits_lm[:, :-1, :].contiguous(), dec_self_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mAaKXoNWr8t",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Pretrain Data 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJhVouZXW2lK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" doc별 pretrain 데이터 생성 \"\"\"\n",
        "def create_pretrain_instances(doc, n_seq):\n",
        "    # for [BOS], [EOS]\n",
        "    max_seq = n_seq - 2\n",
        "    tgt_seq = max_seq\n",
        "    \n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i]) # line\n",
        "        current_length += len(doc[i])\n",
        "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
        "            if 0 < len(current_chunk):\n",
        "                tokens = []\n",
        "                for chunk in current_chunk: tokens.extend(chunk)\n",
        "                tokens = tokens[:tgt_seq]\n",
        "                if 1 < len(tokens):\n",
        "                    instance = {\n",
        "                        \"tokens\": [\"[BOS]\"] + tokens + [\"[EOS]\"],\n",
        "                    }\n",
        "                    instances.append(instance)\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "    return instances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLrMBAInW76M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터 생성 \"\"\"\n",
        "def make_pretrain_data(vocab, in_file, out_file, n_seq):\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "\n",
        "    docs = []\n",
        "    with open(in_file, \"r\") as f:\n",
        "        doc = []\n",
        "        with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "            for i, line in enumerate(f):\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if 0 < len(doc):\n",
        "                        docs.append(doc)\n",
        "                        doc = []\n",
        "                        # 메모리 사용량을 줄이기 위해 100,000개만 처리 함\n",
        "                        if 100000 < len(docs): break\n",
        "                else:\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "                pbar.update(1)\n",
        "        if doc:\n",
        "            docs.append(doc)\n",
        "\n",
        "    with open(out_file, \"w\") as out_f:\n",
        "        with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\n",
        "            for i, doc in enumerate(docs):\n",
        "                instances = create_pretrain_instances(doc, n_seq)\n",
        "                for instance in instances:\n",
        "                    out_f.write(json.dumps(instance))\n",
        "                    out_f.write(\"\\n\")\n",
        "                pbar.update(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erCb80yEXFxs",
        "colab_type": "code",
        "outputId": "f7fb191b-8de0-4036-bced-15207c8ee079",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "8dc295127c4f4a28a8a13b78022ce6b3",
            "ec7bc20677ba4441a629ec6af1d57e37",
            "716a88c4f7e9498fb79c40794023b127",
            "788a646aae6f498ab29f309f6d6c9f11",
            "d88bf438f4c84fb7b2e6f4335eb80ba9",
            "af03fa62ebce434398b7c3e38f72c127",
            "a8bf86c7730f4d13931b4d3fb7804920",
            "6a232a1d965049d7b619890f0dbd79a5",
            "4b1caee6eaa94486832d3963b265fa50",
            "f6e9015a0b90484f8d911d9e4cf84cf0",
            "ece11f61476040ab9d2b17d27bc58c3e",
            "398891195001409fa4c543afeec5a82e",
            "b8830e63a63e4eef8d4f029a70e17b0a",
            "9e5c7eb7c27546fab9bad2b799da7592",
            "c30720aa36d04543817755e2952ded0f",
            "4c03a6bc3c194ec085ae3164480ac50a"
          ]
        }
      },
      "source": [
        "in_file = f\"{data_dir}/kowiki.txt\"\n",
        "out_file = f\"{data_dir}/kowiki_gpt.json\"\n",
        "n_seq = 256\n",
        "\n",
        "if not os.path.isfile(out_file):\n",
        "    make_pretrain_data(vocab, in_file, out_file, n_seq)\n",
        "else:\n",
        "    print(f\"{out_file} exists\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dc295127c4f4a28a8a13b78022ce6b3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Loading', max=3724301, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b1caee6eaa94486832d3963b265fa50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Making', max=100001, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnFPOOjQvO0q",
        "colab_type": "text"
      },
      "source": [
        "#### 10. Pretrain Data\n",
        "GPT Pretrain Data 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDM8rA-AwjcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터셋 \"\"\"\n",
        "class PretrainDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.sentences = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "                for i, line in enumerate(f):\n",
        "                    instance = json.loads(line)\n",
        "                    self.sentences.append([vocab.piece_to_id(p) for p in instance[\"tokens\"]])\n",
        "                    pbar.update(1)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.sentences[item]), torch.tensor(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oeSF6b7IPhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain data collate_fn \"\"\"\n",
        "def pretrin_collate_fn(inputs):\n",
        "    dec_inputs, item = list(zip(*inputs))\n",
        "\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        dec_inputs,\n",
        "        torch.stack(item, dim=0),\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSCF-Q-JISzE",
        "colab_type": "code",
        "outputId": "47b98d7e-41e9-43d8-d725-b840cde07efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "684d0bd53da8464585ca2718153c7116",
            "dfbee92b558f46368b5021ac09ff2ae2",
            "9a23522159434afbae95dff95a2642e7",
            "c745fe33b1974f22ad88c3d89e601311",
            "a4939f594ece433cba487426e4f91597",
            "46e7639230f24233a4c49719844fdd8f",
            "9b3f56d392b2436c857c49d10984e040",
            "0195a06afe464ff7868ea718edb40c1b"
          ]
        }
      },
      "source": [
        "\"\"\" pretrain 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_gpt.json\")\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "684d0bd53da8464585ca2718153c7116",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Loading', max=239311, style=ProgressStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG7wZFuVGp2G",
        "colab_type": "text"
      },
      "source": [
        "#### 11. Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GdZ7oYmGqZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm_notebook(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            dec_inputs, _ = map(lambda v: v.to(config.device), value)\n",
        "            labels_lm = dec_inputs[:, 1:].contiguous()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(dec_inputs)\n",
        "            logits_lm = outputs[0]\n",
        "\n",
        "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
        "            loss = loss_lm \n",
        "\n",
        "            loss_val = loss_lm.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjal3VkSK6rw",
        "colab_type": "code",
        "outputId": "8e043670-5c53-46fe-eb5e-9252c0452619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 20"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_dec_vocab': 8007, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL8bhIxlGz53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GPTPretrain(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_gpt_pretrain.pth\"\n",
        "best_epoch, best_loss = 0, 0\n",
        "if os.path.isfile(save_pretrain):\n",
        "    best_epoch, best_loss = model.gpt.load(save_pretrain)\n",
        "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
        "    best_epoch += 1\n",
        "\n",
        "model.to(config.device)\n",
        "\n",
        "criterion_lm = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n",
        "offset = best_epoch\n",
        "for step in trange(n_epoch, desc=\"Epoch\"):\n",
        "    epoch = step + offset\n",
        "    loss = train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader)\n",
        "    losses.append(loss)\n",
        "    model.gpt.save(epoch, loss, save_pretrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWisHCprMJtk",
        "colab_type": "code",
        "outputId": "07d77927-9a42-42f4-a5eb-79e36ab0b45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        }
      },
      "source": [
        "# data\n",
        "data = {\n",
        "    \"loss\": losses\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses, label=\"loss\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.050916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.016291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.580410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.262791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.107253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.965728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6.836463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6.716375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6.603737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6.494982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>6.394099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>6.304632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.229628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.167107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.116405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.074798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>6.043476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>6.018946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>6.002548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>5.994518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss\n",
              "0   20.050916\n",
              "1    9.016291\n",
              "2    7.580410\n",
              "3    7.262791\n",
              "4    7.107253\n",
              "5    6.965728\n",
              "6    6.836463\n",
              "7    6.716375\n",
              "8    6.603737\n",
              "9    6.494982\n",
              "10   6.394099\n",
              "11   6.304632\n",
              "12   6.229628\n",
              "13   6.167107\n",
              "14   6.116405\n",
              "15   6.074798\n",
              "16   6.043476\n",
              "17   6.018946\n",
              "18   6.002548\n",
              "19   5.994518"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAEGCAYAAACeiKhrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB0IzAAAAMAdCMwAAADAHQjMAAAAwh/8P14CaGtTGmBYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}