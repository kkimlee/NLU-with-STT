{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81YQ41Jq3ioY",
        "colab_type": "text"
      },
      "source": [
        "## GPT 구현 과정 (2/2)\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2019-12-30/gpt-model-downstream.png)\n",
        "\n",
        "GPT 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (2/3)](https://paul-hyun.github.io/transformer-02/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (3/3)](https://paul-hyun.github.io/transformer-03/)\n",
        "- [GPT(Generative Pre-Training) 구현하기 (1/2)](https://paul-hyun.github.io/gpt-01/)\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRRoo-bl4G_P",
        "colab_type": "text"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCCS8nPM4KZu",
        "colab_type": "code",
        "outputId": "a3561316-3f5e-428c-9127-d5079a598561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=94de32b607beee5f9d86b8116b7884d66c678b5d8e504ffe3fd193ee7ddc8464\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTSjMFUn4XUn",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다.\n",
        "\n",
        "학습관련 [데이터 및 결과 파일](https://drive.google.com/open?id=15XGr-L-W6DSoR5TbniPMJASPsA0IDTiN)을 참고 하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnP2WIF83a10",
        "colab_type": "code",
        "outputId": "6102086c-c749-4f9a-dcb2-de097e68972f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-JuqiLd4eTg",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHPMeWxJ4fc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awf2SXuQ4zj0",
        "colab_type": "text"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk2mg8dO44bo",
        "colab_type": "code",
        "outputId": "e2b0a448-d1fb-4b98-c435-fa8d0bc06d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n",
            "kowiki.txt\n",
            "kowiki_gpt.json\n",
            "save_gpt_pretrain.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNEHoBw046_r",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "\n",
        "[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liXKjo4B4-2I",
        "colab_type": "code",
        "outputId": "1e8bcd6a-9e25-4dea-e8a3-ecf3b4d66dd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sSGFxCl5Chp",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Config\n",
        "\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OGdB1HN5CDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLT7pzxa5IFA",
        "colab_type": "code",
        "outputId": "9981e29c-7fe8-47e3-e0cf-242c42dc29db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_dec_vocab\": len(vocab),\n",
        "    \"n_dec_seq\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_dec_vocab': 8007, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEeHBOSf5M7Z",
        "colab_type": "text"
      },
      "source": [
        "#### 6. GPT\n",
        "\n",
        "GPT Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR9Yz5Hf5Rci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "\n",
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRRKm6mP5YlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" decoder layer \"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, dec_inputs, self_attn_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(self_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(self_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob\n",
        "\n",
        "\n",
        "\"\"\" decoder \"\"\"\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "    \n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
        "\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n",
        "\n",
        "        self_attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq)\n",
        "            dec_outputs, self_attn_prob = layer(dec_outputs, dec_self_attn_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, self_attn_probs\n",
        "\n",
        "\n",
        "\"\"\" gpt \"\"\"\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.decoder = Decoder(self.config)\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.decoder(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return dec_outputs, dec_self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxBxdffT5jgM",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Naver 영화 분류 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UZfJ4cA5vED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" naver movie classfication \"\"\"\n",
        "class MovieClassification(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.gpt = GPT(self.config)\n",
        "        # lm\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_dec_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.gpt.decoder.dec_emb.weight\n",
        "        # classfier\n",
        "        self.projection_cls = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
        "    \n",
        "    def forward(self, dec_inputs):\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        dec_outputs, dec_self_attn_probs = self.gpt(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_vocab)\n",
        "        logits_lm = self.projection_lm(dec_outputs)\n",
        "        # (bs, d_hidn)\n",
        "        dec_outputs = dec_outputs[:, -1].contiguous()\n",
        "        # (bs, n_output)\n",
        "        logits_cls = self.projection_cls(dec_outputs)\n",
        "        # (bs, n_dec_seq - 1, n_dec_vocab), (bs, n_output), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
        "        return logits_lm[:, :-1, :].contiguous(), logits_cls, dec_self_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mfdsArh6ACW",
        "colab_type": "text"
      },
      "source": [
        "#### 8. 네이버 영화 분류 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCrJb3986Bsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 영화 분류 데이터셋 \"\"\"\n",
        "class MovieDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                data = json.loads(line)\n",
        "                self.labels.append(data[\"label\"])\n",
        "                self.sentences.append([vocab.piece_to_id(\"[BOS]\")] + [vocab.piece_to_id(p) for p in data[\"doc\"]] + [vocab.piece_to_id(\"[EOS]\")])\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.sentences)\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.sentences[item]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeZRPgX86IAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" movie data collate_fn \"\"\"\n",
        "def movie_collate_fn(inputs):\n",
        "    labels, dec_inputs = list(zip(*inputs))\n",
        "\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels, dim=0),\n",
        "        dec_inputs,\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELEkz72f6LWM",
        "colab_type": "code",
        "outputId": "099131c5-6b57-4877-ff83-4a84210d2b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\" 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "train_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_train.json\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
        "test_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_test.json\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/Data/transformer-evolution/ratings_train.json: 100%|██████████| 149995/149995 [00:03<00:00, 42295.68 lines/s]\n",
            "Loading /content/drive/My Drive/Data/transformer-evolution/ratings_test.json: 100%|██████████| 49997/49997 [00:01<00:00, 44278.37 lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LQicLLH6SjV",
        "colab_type": "text"
      },
      "source": [
        "#### 9. 네이버 영화 분류 데이터 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGSeFztV6aZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 평가 \"\"\"\n",
        "def eval_epoch(config, model, data_loader):\n",
        "    matchs = []\n",
        "    model.eval()\n",
        "\n",
        "    n_word_total = 0\n",
        "    n_correct_total = 0\n",
        "    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
        "        for i, value in enumerate(data_loader):\n",
        "            labels, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            outputs = model(dec_inputs)\n",
        "            logits_cls = outputs[1]\n",
        "            _, indices = logits_cls.max(1)\n",
        "\n",
        "            match = torch.eq(indices, labels).detach()\n",
        "            matchs.extend(match.cpu())\n",
        "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
        "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFWTUIR66ftW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(dec_inputs)\n",
        "            logits_cls = outputs[1]\n",
        "\n",
        "            loss_cls = criterion_cls(logits_cls, labels)\n",
        "            loss = loss_cls\n",
        "\n",
        "            loss_val = loss_cls.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn1k7DA26jqd",
        "colab_type": "code",
        "outputId": "eee1fea8-daac-418b-c7d8-f2d6a9bdd5f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config.n_output = 2\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_dec_vocab': 8007, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda'), 'n_output': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E14Aflfr6ncx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model):\n",
        "    model.to(config.device)\n",
        "\n",
        "    criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_epoch, best_loss, best_score = 0, 0, 0\n",
        "    losses, scores = [], []\n",
        "    for epoch in range(n_epoch):\n",
        "        loss = train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader)\n",
        "        score = eval_epoch(config, model, test_loader)\n",
        "\n",
        "        losses.append(loss)\n",
        "        scores.append(score)\n",
        "\n",
        "        if best_score < score:\n",
        "            best_epoch, best_loss, best_score = epoch, loss, score\n",
        "    print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")\n",
        "    return losses, scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD9vVobmAad2",
        "colab_type": "text"
      },
      "source": [
        "###### Pretrain 없이 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fldSawzz7wUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MovieClassification(config)\n",
        "\n",
        "losses_00, scores_00 = train(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHTz0Y62AhYT",
        "colab_type": "text"
      },
      "source": [
        "###### Pretrain을 한 후 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkpvZ96X7w0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MovieClassification(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_gpt_pretrain.pth\"\n",
        "model.gpt.load(save_pretrain)\n",
        "\n",
        "losses_20, scores_20 = train(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlJEPOFi07qW",
        "colab_type": "text"
      },
      "source": [
        "#### 10. Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVDJVY9asQsO",
        "colab_type": "code",
        "outputId": "2154eb92-d684-4e16-f386-e5f0eb5fd735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "# table\n",
        "data = {\n",
        "    \"loss_00\": losses_00,\n",
        "    \"socre_00\": scores_00,\n",
        "    \"loss_20\": losses_20,\n",
        "    \"socre_20\": scores_20,\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(scores_00, label=\"score_00\")\n",
        "plt.plot(scores_20, label=\"score_20\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_00</th>\n",
              "      <th>socre_00</th>\n",
              "      <th>loss_20</th>\n",
              "      <th>socre_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.486320</td>\n",
              "      <td>0.803188</td>\n",
              "      <td>0.496960</td>\n",
              "      <td>0.798968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.406357</td>\n",
              "      <td>0.812149</td>\n",
              "      <td>0.409752</td>\n",
              "      <td>0.811909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.380282</td>\n",
              "      <td>0.823389</td>\n",
              "      <td>0.379406</td>\n",
              "      <td>0.824189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.358909</td>\n",
              "      <td>0.829450</td>\n",
              "      <td>0.358584</td>\n",
              "      <td>0.831750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.340809</td>\n",
              "      <td>0.832690</td>\n",
              "      <td>0.340274</td>\n",
              "      <td>0.837650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.324291</td>\n",
              "      <td>0.835490</td>\n",
              "      <td>0.323264</td>\n",
              "      <td>0.839230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.306918</td>\n",
              "      <td>0.837550</td>\n",
              "      <td>0.310658</td>\n",
              "      <td>0.836510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.290276</td>\n",
              "      <td>0.837310</td>\n",
              "      <td>0.297167</td>\n",
              "      <td>0.843771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.274559</td>\n",
              "      <td>0.839150</td>\n",
              "      <td>0.284450</td>\n",
              "      <td>0.839530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.256189</td>\n",
              "      <td>0.838730</td>\n",
              "      <td>0.272207</td>\n",
              "      <td>0.838950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    loss_00  socre_00   loss_20  socre_20\n",
              "0  0.486320  0.803188  0.496960  0.798968\n",
              "1  0.406357  0.812149  0.409752  0.811909\n",
              "2  0.380282  0.823389  0.379406  0.824189\n",
              "3  0.358909  0.829450  0.358584  0.831750\n",
              "4  0.340809  0.832690  0.340274  0.837650\n",
              "5  0.324291  0.835490  0.323264  0.839230\n",
              "6  0.306918  0.837550  0.310658  0.836510\n",
              "7  0.290276  0.837310  0.297167  0.843771\n",
              "8  0.274559  0.839150  0.284450  0.839530\n",
              "9  0.256189  0.838730  0.272207  0.838950"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAEGCAYAAACuBLlKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}