{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfpg-n2gNgtB",
        "colab_type": "text"
      },
      "source": [
        "## BERT 구현 과정 (2/2)\n",
        "![](https://raw.githubusercontent.com/paul-hyun/paul-hyun.github.io/master/assets/2020-01-02/bert-classification.png)\n",
        "\n",
        "BERT 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (2/3)](https://paul-hyun.github.io/transformer-02/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (3/3)](https://paul-hyun.github.io/transformer-03/)\n",
        "- [BERT(Bidirectional Encoder Representations from Transformers) 구현하기 (1/2)](https://paul-hyun.github.io/bert-01/)\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4fLocKzS8qH",
        "colab_type": "text"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP4qW5w6TAXe",
        "colab_type": "code",
        "outputId": "b361c562-1f45-4f3d-9425-d6322bd4e902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 4.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=fbe3e0ed3f7e6c70494e79fc604efd380b7d12ea3279369dae9a5ac2c3c923e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZs93qCwS_bM",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다.\n",
        "\n",
        "학습관련 [데이터 및 결과 파일](https://drive.google.com/open?id=15XGr-L-W6DSoR5TbniPMJASPsA0IDTiN)을 참고 하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XR4LcDdNfnW",
        "colab_type": "code",
        "outputId": "f257e7d1-3b49-44aa-8038-79b5d79a29a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMgpP6fjTJF8",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRgT80wpTJiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRrdaSJ_TNAf",
        "colab_type": "text"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfWB9L0_TQlP",
        "colab_type": "code",
        "outputId": "1a2370d6-ade6-4676-fae8-57b0e5c62efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n",
            "kowiki.txt\n",
            "kowiki_gpt.json\n",
            "save_gpt_pretrain.pth\n",
            "kowiki_bert_0.json\n",
            "save_bert_pretrain.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUOwhKMyTXNQ",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "\n",
        "[Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)를 통해 만들어 놓은 vocab을 로딩 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LX6VgIkTaKV",
        "colab_type": "code",
        "outputId": "d739a631-7545-40cb-e6c3-a231b4a6a401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMgziU4ATcyN",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Config\n",
        "\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDcRg9V0Tdc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUztpEf6Tfx1",
        "colab_type": "code",
        "outputId": "df1b2b58-4c9f-4f7d-c585-a1c7cd5146ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_enc_vocab\": len(vocab),\n",
        "    \"n_enc_seq\": 256,\n",
        "    \"n_seg_type\": 2,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j93X24LtTijG",
        "colab_type": "text"
      },
      "source": [
        "#### 6. BERT\n",
        "\n",
        "BERT Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_41WubQUImx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position encoding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
        "\n",
        "    return sinusoid_table\n",
        "\n",
        "\n",
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDXUeMKoULa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder layer \"\"\"\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        return ffn_outputs, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" encoder \"\"\"\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n",
        "        self.pos_emb = nn.Embedding(self.config.n_enc_seq + 1, self.config.d_hidn)\n",
        "        self.seg_emb = nn.Embedding(self.config.n_seg_type, self.config.d_hidn)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "        pos_mask = inputs.eq(self.config.i_pad)\n",
        "        positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        outputs = self.enc_emb(inputs) + self.pos_emb(positions)  + self.seg_emb(segments)\n",
        "\n",
        "        # (bs, n_enc_seq, n_enc_seq)\n",
        "        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "            outputs, attn_prob = layer(outputs, attn_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, attn_probs\n",
        "\n",
        "\n",
        "\"\"\" bert \"\"\"\n",
        "class BERT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.encoder = Encoder(self.config)\n",
        "\n",
        "        self.linear = nn.Linear(config.d_hidn, config.d_hidn)\n",
        "        self.activation = torch.tanh\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        # (bs, n_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        outputs, self_attn_probs = self.encoder(inputs, segments)\n",
        "        # (bs, d_hidn)\n",
        "        outputs_cls = outputs[:, 0].contiguous()\n",
        "        outputs_cls = self.linear(outputs_cls)\n",
        "        outputs_cls = self.activation(outputs_cls)\n",
        "        # (bs, n_enc_seq, n_enc_vocab), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return outputs, outputs_cls, self_attn_probs\n",
        "    \n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZQyVfnJUcXH",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Naver 영화 분류 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIu5UyLUUdMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" naver movie classfication \"\"\"\n",
        "class MovieClassification(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BERT(self.config)\n",
        "        # classfier\n",
        "        self.projection_cls = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
        "    \n",
        "    def forward(self, inputs, segments):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        outputs, outputs_cls, attn_probs = self.bert(inputs, segments)\n",
        "        # (bs, n_output)\n",
        "        logits_cls = self.projection_cls(outputs_cls)\n",
        "        # (bs, n_output), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return logits_cls, attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_DfRSm3Uzg3",
        "colab_type": "text"
      },
      "source": [
        "#### 8. 네이버 영화 분류 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F8q2PatU0KH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 영화 분류 데이터셋 \"\"\"\n",
        "class MovieDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.sentences = []\n",
        "        self.segments = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=\"Loading Dataset\", unit=\" lines\")):\n",
        "                data = json.loads(line)\n",
        "                self.labels.append(data[\"label\"])\n",
        "                sentence = [vocab.piece_to_id(\"[CLS]\")] + [vocab.piece_to_id(p) for p in data[\"doc\"]] + [vocab.piece_to_id(\"[SEP]\")]\n",
        "                self.sentences.append(sentence)\n",
        "                self.segments.append([0] * len(sentence))\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.sentences)\n",
        "        assert len(self.labels) == len(self.segments)\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.sentences[item]),\n",
        "                torch.tensor(self.segments[item]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIUF3NDiU9JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" movie data collate_fn \"\"\"\n",
        "def movie_collate_fn(inputs):\n",
        "    labels, inputs, segments = list(zip(*inputs))\n",
        "\n",
        "    inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "    segments = torch.nn.utils.rnn.pad_sequence(segments, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        torch.stack(labels, dim=0),\n",
        "        inputs,\n",
        "        segments,\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7h4x5WAVE-Y",
        "colab_type": "code",
        "outputId": "eaa9343a-3b77-4c75-81c4-b5f0e60a59ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\" 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "train_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_train.json\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
        "test_dataset = MovieDataSet(vocab, f\"{data_dir}/ratings_test.json\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Dataset: 100%|██████████| 149995/149995 [00:04<00:00, 30768.76 lines/s]\n",
            "Loading Dataset: 100%|██████████| 49997/49997 [00:01<00:00, 28653.14 lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ROkwVAZVMBq",
        "colab_type": "text"
      },
      "source": [
        "#### 9. 네이버 영화 분류 데이터 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uk8i_COVMqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 평가 \"\"\"\n",
        "def eval_epoch(config, model, data_loader):\n",
        "    matchs = []\n",
        "    model.eval()\n",
        "\n",
        "    n_word_total = 0\n",
        "    n_correct_total = 0\n",
        "    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
        "        for i, value in enumerate(data_loader):\n",
        "            labels, inputs, segments = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            outputs = model(inputs, segments)\n",
        "            logits_cls = outputs[0]\n",
        "            _, indices = logits_cls.max(1)\n",
        "\n",
        "            match = torch.eq(indices, labels).detach()\n",
        "            matchs.extend(match.cpu())\n",
        "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
        "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDuh_wmmVWSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels, inputs, segments = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, segments)\n",
        "            logits_cls = outputs[0]\n",
        "\n",
        "            loss_cls = criterion_cls(logits_cls, labels)\n",
        "            loss = loss_cls\n",
        "\n",
        "            loss_val = loss_cls.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8zkUfOmVjNo",
        "colab_type": "code",
        "outputId": "ae28e3c5-d632-4ef2-8661-7e81b6c9f6b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "config.n_output = 2\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 10"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_enc_vocab': 8007, 'n_enc_seq': 256, 'n_seg_type': 2, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda'), 'n_output': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wZhTd_zVo8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model):\n",
        "    model.to(config.device)\n",
        "\n",
        "    criterion_cls = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    best_epoch, best_loss, best_score = 0, 0, 0\n",
        "    losses, scores = [], []\n",
        "    for epoch in range(n_epoch):\n",
        "        loss = train_epoch(config, epoch, model, criterion_cls, optimizer, train_loader)\n",
        "        score = eval_epoch(config, model, test_loader)\n",
        "\n",
        "        losses.append(loss)\n",
        "        scores.append(score)\n",
        "\n",
        "        if best_score < score:\n",
        "            best_epoch, best_loss, best_score = epoch, loss, score\n",
        "    print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")\n",
        "    return losses, scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui2zgSlUVxDw",
        "colab_type": "text"
      },
      "source": [
        "###### Pretrain 없이 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pojS0xVsVv_y",
        "colab_type": "code",
        "outputId": "bd584472-1e1b-4dbc-ae97-b9c10b911a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = MovieClassification(config)\n",
        "\n",
        "losses_00, scores_00 = train(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train(0): 100%|██████████| 1172/1172 [03:59<00:00,  5.31it/s, Loss: 0.454 (0.522)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.55it/s, Acc: 0.784]\n",
            "Train(1): 100%|██████████| 1172/1172 [03:58<00:00,  5.06it/s, Loss: 0.445 (0.436)]\n",
            "Valid: 100%|██████████| 391/391 [00:48<00:00,  5.54it/s, Acc: 0.796]\n",
            "Train(2): 100%|██████████| 1172/1172 [03:59<00:00,  5.19it/s, Loss: 0.351 (0.409)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.70it/s, Acc: 0.804]\n",
            "Train(3): 100%|██████████| 1172/1172 [03:59<00:00,  5.41it/s, Loss: 0.404 (0.389)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.66it/s, Acc: 0.811]\n",
            "Train(4): 100%|██████████| 1172/1172 [03:59<00:00,  5.32it/s, Loss: 0.397 (0.371)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.54it/s, Acc: 0.814]\n",
            "Train(5): 100%|██████████| 1172/1172 [04:01<00:00,  5.10it/s, Loss: 0.366 (0.356)]\n",
            "Valid: 100%|██████████| 391/391 [00:50<00:00,  5.75it/s, Acc: 0.811]\n",
            "Train(6): 100%|██████████| 1172/1172 [03:59<00:00,  5.06it/s, Loss: 0.451 (0.341)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.48it/s, Acc: 0.815]\n",
            "Train(7): 100%|██████████| 1172/1172 [04:00<00:00,  4.93it/s, Loss: 0.303 (0.324)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.85it/s, Acc: 0.814]\n",
            "Train(8): 100%|██████████| 1172/1172 [04:00<00:00,  4.96it/s, Loss: 0.365 (0.307)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.69it/s, Acc: 0.816]\n",
            "Train(9): 100%|██████████| 1172/1172 [04:00<00:00,  4.95it/s, Loss: 0.353 (0.289)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.33it/s, Acc: 0.818]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>> epoch=9, loss=0.28937, socre=0.81795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJALhcUrV-5T",
        "colab_type": "text"
      },
      "source": [
        "###### Pretrain을 한 후 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvGZZyUBV2pI",
        "colab_type": "code",
        "outputId": "29b6338d-10bf-4ee9-d49a-444ca02a1042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = MovieClassification(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_bert_pretrain.pth\"\n",
        "model.bert.load(save_pretrain)\n",
        "\n",
        "losses_20, scores_20 = train(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train(0): 100%|██████████| 1172/1172 [04:00<00:00,  5.09it/s, Loss: 0.526 (0.515)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.61it/s, Acc: 0.782]\n",
            "Train(1): 100%|██████████| 1172/1172 [03:59<00:00,  5.10it/s, Loss: 0.428 (0.435)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.50it/s, Acc: 0.799]\n",
            "Train(2): 100%|██████████| 1172/1172 [03:59<00:00,  5.08it/s, Loss: 0.457 (0.405)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.46it/s, Acc: 0.810]\n",
            "Train(3): 100%|██████████| 1172/1172 [03:59<00:00,  5.05it/s, Loss: 0.394 (0.383)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.44it/s, Acc: 0.814]\n",
            "Train(4): 100%|██████████| 1172/1172 [04:00<00:00,  4.55it/s, Loss: 0.372 (0.364)]\n",
            "Valid: 100%|██████████| 391/391 [00:48<00:00,  5.49it/s, Acc: 0.816]\n",
            "Train(5): 100%|██████████| 1172/1172 [04:00<00:00,  5.13it/s, Loss: 0.379 (0.348)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.66it/s, Acc: 0.818]\n",
            "Train(6): 100%|██████████| 1172/1172 [04:00<00:00,  4.45it/s, Loss: 0.403 (0.330)]\n",
            "Valid: 100%|██████████| 391/391 [00:49<00:00,  5.41it/s, Acc: 0.820]\n",
            "Train(7): 100%|██████████| 1172/1172 [04:00<00:00,  5.10it/s, Loss: 0.514 (0.311)]\n",
            "Valid: 100%|██████████| 391/391 [00:50<00:00,  5.55it/s, Acc: 0.824]\n",
            "Train(8): 100%|██████████| 1172/1172 [04:01<00:00,  4.85it/s, Loss: 0.229 (0.295)]\n",
            "Valid: 100%|██████████| 391/391 [00:50<00:00,  5.45it/s, Acc: 0.823]\n",
            "Train(9): 100%|██████████| 1172/1172 [04:03<00:00,  4.87it/s, Loss: 0.277 (0.277)]\n",
            "Valid: 100%|██████████| 391/391 [00:50<00:00,  5.20it/s, Acc: 0.818]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>>> epoch=7, loss=0.31119, socre=0.82397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0_DtGYqWCvs",
        "colab_type": "text"
      },
      "source": [
        "#### 10. Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZnPu0tgWIUI",
        "colab_type": "code",
        "outputId": "b2322c25-9c01-4e5c-898d-e83634c661b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "# table\n",
        "data = {\n",
        "    \"loss_00\": losses_00,\n",
        "    \"socre_00\": scores_00,\n",
        "    \"loss_20\": losses_20,\n",
        "    \"socre_20\": scores_20,\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(scores_00, label=\"score_00\")\n",
        "plt.plot(scores_20, label=\"score_20\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss_00</th>\n",
              "      <th>socre_00</th>\n",
              "      <th>loss_20</th>\n",
              "      <th>socre_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.522093</td>\n",
              "      <td>0.783687</td>\n",
              "      <td>0.515065</td>\n",
              "      <td>0.782307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.436096</td>\n",
              "      <td>0.795608</td>\n",
              "      <td>0.434717</td>\n",
              "      <td>0.798528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.408585</td>\n",
              "      <td>0.804388</td>\n",
              "      <td>0.405332</td>\n",
              "      <td>0.809989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.388935</td>\n",
              "      <td>0.810749</td>\n",
              "      <td>0.383013</td>\n",
              "      <td>0.814149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.371047</td>\n",
              "      <td>0.813969</td>\n",
              "      <td>0.364083</td>\n",
              "      <td>0.816289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.355533</td>\n",
              "      <td>0.810529</td>\n",
              "      <td>0.347914</td>\n",
              "      <td>0.817629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.341048</td>\n",
              "      <td>0.815309</td>\n",
              "      <td>0.329771</td>\n",
              "      <td>0.820329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.324362</td>\n",
              "      <td>0.813649</td>\n",
              "      <td>0.311193</td>\n",
              "      <td>0.823969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.307140</td>\n",
              "      <td>0.816129</td>\n",
              "      <td>0.295256</td>\n",
              "      <td>0.822689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.289369</td>\n",
              "      <td>0.817949</td>\n",
              "      <td>0.276582</td>\n",
              "      <td>0.818469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    loss_00  socre_00   loss_20  socre_20\n",
              "0  0.522093  0.783687  0.515065  0.782307\n",
              "1  0.436096  0.795608  0.434717  0.798528\n",
              "2  0.408585  0.804388  0.405332  0.809989\n",
              "3  0.388935  0.810749  0.383013  0.814149\n",
              "4  0.371047  0.813969  0.364083  0.816289\n",
              "5  0.355533  0.810529  0.347914  0.817629\n",
              "6  0.341048  0.815309  0.329771  0.820329\n",
              "7  0.324362  0.813649  0.311193  0.823969\n",
              "8  0.307140  0.816129  0.295256  0.822689\n",
              "9  0.289369  0.817949  0.276582  0.818469"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAEGCAYAAACuBLlKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP8g1jr0fAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}