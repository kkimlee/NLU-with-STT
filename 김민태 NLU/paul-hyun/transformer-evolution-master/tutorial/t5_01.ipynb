{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "t5-01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f893cef3d474a15aab57e168205eedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10c886e2cf7c4eb5bca64b399098d168",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4296d0ce29a4c7f8e575506c3835911",
              "IPY_MODEL_26daeaba3b04460d87f5e9cfd8d85563"
            ]
          }
        },
        "10c886e2cf7c4eb5bca64b399098d168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4296d0ce29a4c7f8e575506c3835911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8124022674d485c9316ec64b2c456c9",
            "_dom_classes": [],
            "description": "Loading",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 3724301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1039716,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddbba6da173642558aafa24f121bef2b"
          }
        },
        "26daeaba3b04460d87f5e9cfd8d85563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b493c59c5e8d43649d2ed8484c909235",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28% 1039716/3724301 [01:23&lt;03:35, 12455.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69dffc7115af4e6eba4c1739db730db1"
          }
        },
        "e8124022674d485c9316ec64b2c456c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddbba6da173642558aafa24f121bef2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b493c59c5e8d43649d2ed8484c909235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69dffc7115af4e6eba4c1739db730db1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zfpg-n2gNgtB",
        "colab_type": "text"
      },
      "source": [
        "## T5 구현 과정 (2/2)\n",
        "T5 모델 구현에 대한 설명 입니다.\n",
        "\n",
        "이 내용을 확인하기 전 아래 내용을 확인하시기 바랍니다.\n",
        "- [Sentencepiece를 활용해 Vocab 만들기](https://paul-hyun.github.io/vocab-with-sentencepiece/)\n",
        "- [Naver 영화리뷰 감정분석 데이터 전처리 하기](https://paul-hyun.github.io/preprocess-nsmc/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (1/3)](https://paul-hyun.github.io/transformer-01/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (2/3)](https://paul-hyun.github.io/transformer-02/)\n",
        "- [Transformer (Attention Is All You Need) 구현하기 (3/3)](https://paul-hyun.github.io/transformer-03/)\n",
        "\n",
        "\n",
        "[Colab](https://colab.research.google.com/)에서 실행 했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4fLocKzS8qH",
        "colab_type": "text"
      },
      "source": [
        "#### 0. Pip Install\n",
        "필요한 패키지를 pip를 이용해서 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP4qW5w6TAXe",
        "colab_type": "code",
        "outputId": "54e19570-6235-4dc3-dfa7-b0c81eb940fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 12.2MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 5.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 5.8MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 6.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 7.2MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 7.5MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.85\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=38731a17f36f72fc68155ad636a36e987351441a7fc0b1ac5e4463c28d9c5641\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZs93qCwS_bM",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Google Drive Mount\n",
        "Colab에서는 컴퓨터에 자원에 접근이 불가능 하므로 Google Drive에 파일을 올려 놓은 후 Google Drive를 mount 에서 로컬 디스크처럼 사용 합니다.\n",
        "1. 아래 블럭을 실행하면 나타나는 링크를 클릭하세요.\n",
        "2. Google 계정을 선택 하시고 허용을 누르면 나타나는 코드를 복사하여 아래 박스에 입력한 후 Enter 키를 입력하면 됩니다.\n",
        "\n",
        "학습관련 [데이터 및 결과 파일](https://drive.google.com/open?id=15XGr-L-W6DSoR5TbniPMJASPsA0IDTiN)을 참고 하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XR4LcDdNfnW",
        "colab_type": "code",
        "outputId": "36d28670-e5bb-4880-95d3-579f6ea529f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# data를 저장할 폴더 입니다. 환경에 맞게 수정 하세요.\n",
        "data_dir = \"/content/drive/My Drive/Data/transformer-evolution\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMgpP6fjTJF8",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRgT80wpTJiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from random import random, shuffle, choices, randrange\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRrdaSJ_TNAf",
        "colab_type": "text"
      },
      "source": [
        "#### 3. 폴더의 목록을 확인\n",
        "Google Drive mount가 잘 되었는지 확인하기 위해 data_dir 목록을 확인 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfWB9L0_TQlP",
        "colab_type": "code",
        "outputId": "5012e254-5831-43a3-b585-e33ee1970d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "for f in os.listdir(data_dir):\n",
        "  print(f)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kowiki.csv.gz\n",
            "kowiki.model\n",
            "kowiki.vocab\n",
            "ratings_train.txt\n",
            "ratings_test.txt\n",
            "ratings_train.json\n",
            "ratings_test.json\n",
            "kowiki.txt\n",
            "kowiki_gpt.json\n",
            "save_gpt_pretrain.pth\n",
            "kowiki_bert_0.json\n",
            "save_bert_pretrain.pth\n",
            "kowiki_t5.model\n",
            "kowiki_t5.vocab\n",
            "kowiki_t5_0.json\n",
            "save_t5_pretrain.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUOwhKMyTXNQ",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Vocab 및 입력\n",
        "\n",
        "T5를 위해 vocab을 새로 만들 었습니다. (아래 옵션 참고)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvVMgq0sgMEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spm.SentencePieceTrainer.train(\n",
        "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7 + 26}\" + \n",
        "    \" --model_type=bpe\" +\n",
        "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
        "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
        "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
        "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
        "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
        "    \" --user_defined_symbols=[SEP],[CLS],[MASK],<A>,<B>,<C>,<D>,<E>,<F>,<G>,<H>,<I>,<J>,<K>,<L>,<M>,<N>,<O>,<P>,<Q>,<R>,<S>,<T>,<U>,<V>,<W>,<X>,<Y>,<Z>\") # 기타 추가 토큰"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LX6VgIkTaKV",
        "colab_type": "code",
        "outputId": "a4f39958-3250-49d9-f10f-ba150219c661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vocab loading\n",
        "vocab_file = f\"{data_dir}/kowiki_t5.model\"\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMgziU4ATcyN",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Config\n",
        "\n",
        "모델에 설정 값을 전달하기 위한 config를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDcRg9V0Tdc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" configuration json을 읽어들이는 class \"\"\"\n",
        "class Config(dict): \n",
        "    __getattr__ = dict.__getitem__\n",
        "    __setattr__ = dict.__setitem__\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, file):\n",
        "        with open(file, 'r') as f:\n",
        "            config = json.loads(f.read())\n",
        "            return Config(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUztpEf6Tfx1",
        "colab_type": "code",
        "outputId": "b9c71b1c-3124-4b7b-cf78-3f0ca157507f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = Config({\n",
        "    \"n_vocab\": len(vocab),\n",
        "    \"n_seq\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"d_hidn\": 256,\n",
        "    \"i_pad\": 0,\n",
        "    \"d_ff\": 1024,\n",
        "    \"n_head\": 4,\n",
        "    \"d_head\": 64,\n",
        "    \"dropout\": 0.1,\n",
        "    \"layer_norm_epsilon\": 1e-12\n",
        "})\n",
        "print(config)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_vocab': 8033, 'n_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j93X24LtTijG",
        "colab_type": "text"
      },
      "source": [
        "#### 6. T5\n",
        "\n",
        "T5 Class 및 함수 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_41WubQUImx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" attention pad mask \"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n",
        "    return pad_attn_mask\n",
        "\n",
        "\n",
        "\"\"\" attention decoder mask \"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
        "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
        "    return subsequent_mask\n",
        "\n",
        "\n",
        "\"\"\" scale dot product attention \"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "        self.num_buckets = 32\n",
        "        self.relative_attention_bias = torch.nn.Embedding(self.num_buckets, self.config.n_head)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask, bidirectional=True):\n",
        "        qlen, klen = Q.size(-2), K.size(-2)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        # (1, n_head, n_q_seq, n_k_seq)\n",
        "        position_bias = self.compute_bias(qlen, klen, bidirectional=bidirectional)\n",
        "        scores += position_bias\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        attn_prob = self.dropout(attn_prob)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob\n",
        "    \n",
        "    def compute_bias(self, qlen, klen, bidirectional=True):\n",
        "        context_position = torch.arange(qlen, dtype=torch.long)[:, None]\n",
        "        memory_position = torch.arange(klen, dtype=torch.long)[None, :]\n",
        "        # (qlen, klen)\n",
        "        relative_position = memory_position - context_position\n",
        "        # (qlen, klen)\n",
        "        rp_bucket = self._relative_position_bucket(\n",
        "            relative_position,  # shape (qlen, klen)\n",
        "            num_buckets=self.num_buckets,\n",
        "            bidirectional=bidirectional\n",
        "        )\n",
        "        # (qlen, klen)\n",
        "        rp_bucket = rp_bucket.to(self.relative_attention_bias.weight.device)\n",
        "        # (qlen, klen, n_head)\n",
        "        values = self.relative_attention_bias(rp_bucket)\n",
        "        # (1, n_head, qlen, klen)\n",
        "        values = values.permute([2, 0, 1]).unsqueeze(0)\n",
        "        return values\n",
        "\n",
        "    def _relative_position_bucket(self, relative_position, bidirectional=True, num_buckets=32, max_distance=128):\n",
        "        ret = 0\n",
        "        n = -relative_position\n",
        "        if bidirectional:\n",
        "            num_buckets //= 2\n",
        "            ret += (n < 0).to(torch.long) * num_buckets  # mtf.to_int32(mtf.less(n, 0)) * num_buckets\n",
        "            n = torch.abs(n)\n",
        "        else:\n",
        "            n = torch.max(n, torch.zeros_like(n))\n",
        "\n",
        "        # half of the buckets are for exact increments in positions\n",
        "        max_exact = num_buckets // 2\n",
        "        is_small = n < max_exact\n",
        "\n",
        "        # The other half of the buckets are for logarithmically bigger bins in positions up to max_distance\n",
        "        val_if_large = max_exact + (\n",
        "                torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)\n",
        "        ).to(torch.long)\n",
        "        val_if_large = torch.min(val_if_large, torch.full_like(val_if_large, num_buckets - 1))\n",
        "\n",
        "        ret += torch.where(is_small, n, val_if_large)\n",
        "        return ret\n",
        "\n",
        "\n",
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask, bidirectional=False):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask, bidirectional=bidirectional)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        output = self.dropout(output)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDXUeMKoULa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" encoder layer \"\"\"\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, inputs, attn_mask):\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
        "        att_outputs = self.layer_norm1(inputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(att_outputs)\n",
        "        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n",
        "        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "        return ffn_outputs, attn_prob\n",
        "\n",
        "\n",
        "\"\"\" encoder \"\"\"\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, enc_embd, enc_self_mask):\n",
        "        # (bs, n_enc_seq, d_hidn)\n",
        "        enc_outputs = enc_embd\n",
        "\n",
        "        attn_probs = []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n",
        "            enc_outputs, attn_prob = layer(enc_outputs, enc_self_mask)\n",
        "            attn_probs.append(attn_prob)\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        return enc_outputs, attn_probs\n",
        "\n",
        "\n",
        "\"\"\" decoder layer \"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.self_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.dec_enc_attn = MultiHeadAttention(self.config)\n",
        "        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n",
        "    \n",
        "    def forward(self, dec_inputs, enc_outputs, self_mask, ende_mask):\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n",
        "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_mask, bidirectional=False)\n",
        "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, ende_mask)\n",
        "        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n",
        "        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n",
        "        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
        "        return ffn_outputs, self_attn_prob, dec_enc_attn_prob\n",
        "\n",
        "\n",
        "\"\"\" decoder \"\"\"\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "    \n",
        "    def forward(self, dec_embd, enc_outputs, self_mask, ende_mask):\n",
        "        # (bs, n_dec_seq, d_hidn)\n",
        "        dec_outputs = dec_embd\n",
        "\n",
        "        self_attn_probs, dec_enc_attn_probs = [], []\n",
        "        for layer in self.layers:\n",
        "            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n",
        "            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, self_mask, ende_mask)\n",
        "            self_attn_probs.append(self_attn_prob)\n",
        "            dec_enc_attn_probs.append(dec_enc_attn_prob)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n",
        "        return dec_outputs, self_attn_probs, dec_enc_attn_probs\n",
        "\n",
        "\n",
        "\"\"\" t5 \"\"\"\n",
        "class T5(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.embedding = nn.Embedding(self.config.n_vocab, self.config.d_hidn)\n",
        "        self.encoder = Encoder(self.config)\n",
        "        self.decoder = Decoder(self.config)\n",
        "\n",
        "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_vocab, bias=False)\n",
        "        self.projection_lm.weight = self.embedding.weight\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        enc_embd = self.embedding(enc_inputs)\n",
        "        dec_embd = self.embedding(dec_inputs)\n",
        "\n",
        "        enc_self_mask = get_attn_pad_mask(enc_inputs, enc_inputs, self.config.i_pad)\n",
        "        dec_self_mask = self.get_attn_dec_mask(dec_inputs)\n",
        "        dec_ende_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n",
        "\n",
        "        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n",
        "        enc_outputs, enc_self_attn_probs = self.encoder(enc_embd, enc_self_mask)\n",
        "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_embd, enc_outputs, dec_self_mask, dec_ende_mask)\n",
        "        # (bs, n_dec_seq, n_vocab)\n",
        "        dec_outputs = self.projection_lm(dec_outputs)\n",
        "        # (bs, n_dec_seq, n_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs\n",
        "    \n",
        "    def get_attn_dec_mask(self, dec_inputs):\n",
        "         # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_ahead_mask = get_attn_decoder_mask(dec_inputs)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        dec_self_mask = torch.gt((dec_pad_mask + dec_ahead_mask), 0)\n",
        "        # (bs, n_dec_seq, n_dec_seq)\n",
        "        return dec_self_mask\n",
        "\n",
        "    def save(self, epoch, loss, path):\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            \"state_dict\": self.state_dict()\n",
        "        }, path)\n",
        "    \n",
        "    def load(self, path):\n",
        "        save = torch.load(path)\n",
        "        self.load_state_dict(save[\"state_dict\"])\n",
        "        return save[\"epoch\"], save[\"loss\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZQyVfnJUcXH",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Pretrain 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIu5UyLUUdMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" T5 pretrain \"\"\"\n",
        "class T5Pretrain(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.t5 = T5(self.config)\n",
        "    \n",
        "    def forward(self, enc_inputs, dec_inputs):\n",
        "        # (bs, n_dec_seq, n_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n",
        "        logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.t5(enc_inputs, dec_inputs)\n",
        "        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_DfRSm3Uzg3",
        "colab_type": "text"
      },
      "source": [
        "#### 8. Pretrain Data 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cyywnsK12GB",
        "colab_type": "code",
        "outputId": "39b2c6ee-1625-4a2b-bd82-bf56e20ff459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "SPAN_LEN = 8\n",
        "SPAN_VALUE = np.array([i+1 for i in range(SPAN_LEN)])\n",
        "SPAN_RATIO = np.array([1/i for i in SPAN_VALUE])\n",
        "SPAN_RATIO = SPAN_RATIO / np.sum(SPAN_RATIO)\n",
        "\n",
        "print(f\"평균 mask 길이: {np.sum(SPAN_VALUE * SPAN_RATIO)}\")\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(SPAN_RATIO, label=\"ration\")\n",
        "plt.legend()\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('Ratioo')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "평균 mask 길이: 2.9434954007884366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAEGCAYAAACuBLlKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vR09cBp2yGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" SPAN 길이 \"\"\"\n",
        "def get_span_length():\n",
        "    return choices(SPAN_VALUE, SPAN_RATIO)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F8q2PatU0KH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_pretrain_mask(tokens, mask_cnt):\n",
        "    \"\"\"\n",
        "    마스크 생성\n",
        "    \"\"\"\n",
        "    masks = []\n",
        "    cand_idx = {}\n",
        "    index = 0\n",
        "    for (i, token) in enumerate(tokens):\n",
        "        masks.append(None)\n",
        "        if token == \"[BOS]\" or token == \"[EOS]\":\n",
        "            continue\n",
        "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):\n",
        "            cand_idx[index].append(i)\n",
        "        else:\n",
        "            index += 1\n",
        "            cand_idx[index] = [i]\n",
        "    assert len(masks) == len(tokens)\n",
        "    keys = list(cand_idx.keys())\n",
        "    shuffle(keys)\n",
        "\n",
        "    mask_lms = []\n",
        "    covered_idx = set()\n",
        "    for index in keys:\n",
        "        if len(mask_lms) >= mask_cnt:\n",
        "            break\n",
        "        span_len = get_span_length()\n",
        "        # 남은 토큰개수고 마스크 토큰 캐수보다 작은 경우\n",
        "        if len(cand_idx) <= index + span_len:\n",
        "            continue\n",
        "        index_set = []\n",
        "        # mask할 토큰의 index 저장\n",
        "        for i in range(span_len):\n",
        "            index_set.extend(cand_idx[index + i])\n",
        "        # 마스크 개수 초과 방지\n",
        "        if len(mask_lms) + len(index_set) > mask_cnt:\n",
        "            continue\n",
        "        # 이미 마스크 된 경우가 있는지 확인\n",
        "        is_idx_covered = False\n",
        "        for index in index_set:\n",
        "            if index in covered_idx:\n",
        "                is_idx_covered = True\n",
        "                break\n",
        "        if is_idx_covered:\n",
        "            continue\n",
        "\n",
        "        for index in index_set:\n",
        "            covered_idx.add(index)\n",
        "            masked_token = None\n",
        "            mask_lms.append({\"index\": index, \"span_idx1\": index_set[0] - 1, \"span_idx2\": index_set[-1] + 1, \"label\": tokens[index]})\n",
        "            masks[index] = tokens[index]\n",
        "            tokens[index] = masked_token\n",
        "        # span boundary\n",
        "        covered_idx.add(index_set[0] - 1)\n",
        "        covered_idx.add(index_set[-1] + 1)\n",
        "\n",
        "    enc_input, dec_input = [], []\n",
        "    ascii_index = 65\n",
        "    is_mask = False\n",
        "    for i, token in enumerate(tokens):\n",
        "        if is_mask:\n",
        "            if token is None:\n",
        "                dec_input.append(masks[i])\n",
        "            else:\n",
        "                enc_input.append(token)\n",
        "                is_mask = False\n",
        "        else:\n",
        "            if token is None:\n",
        "                enc_input.append(f\"<{chr(ascii_index)}>\")\n",
        "                dec_input.append(f\"<{chr(ascii_index)}>\")\n",
        "                dec_input.append(masks[i])\n",
        "                ascii_index += 1\n",
        "                is_mask = True\n",
        "            else:\n",
        "                enc_input.append(token)\n",
        "    if 0 < len(dec_input):\n",
        "        dec_input.append(\"<Z>\")\n",
        "    return enc_input, dec_input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7h4x5WAVE-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_pretrain_instances(docs, doc_idx, doc, n_seq, mask_prob):\n",
        "    \"\"\"\n",
        "    doc별 pretrain 데이터 생성\n",
        "    \"\"\"\n",
        "    # for [BOS], [EOS]\n",
        "    max_seq = n_seq - 2\n",
        "    tgt_seq = max_seq\n",
        "\n",
        "    instances = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for i in range(len(doc)):\n",
        "        current_chunk.append(doc[i])  # line\n",
        "        current_length += len(doc[i])\n",
        "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
        "            if 0 < len(current_chunk):\n",
        "                tokens = []\n",
        "                for chunk in current_chunk: tokens.extend(chunk)\n",
        "                tokens = tokens[:tgt_seq]\n",
        "                enc_input, dec_input = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob))\n",
        "\n",
        "                instance = {\n",
        "                    \"enc_input\": enc_input,\n",
        "                    \"dec_input\": dec_input,\n",
        "                }\n",
        "                instances.append(instance)\n",
        "\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "    return instances"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqbLKjIczUQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터 생성 \"\"\"\n",
        "def make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob):\n",
        "    line_cnt = 0\n",
        "    with open(in_file, \"r\") as in_f:\n",
        "        for line in in_f:\n",
        "            line_cnt += 1\n",
        "    \n",
        "    docs = []\n",
        "    with open(in_file, \"r\") as f:\n",
        "        doc = []\n",
        "        with tqdm_notebook(total=line_cnt, desc=f\"Loading\") as pbar:\n",
        "            for i, line in enumerate(f):\n",
        "                line = line.strip()\n",
        "                if line == \"\":\n",
        "                    if 0 < len(doc):\n",
        "                        docs.append(doc)\n",
        "                        doc = []\n",
        "                        # 메모리 사용량을 줄이기 위해 100,000개만 처리 함\n",
        "                        if 100000 < len(docs): break\n",
        "                else:\n",
        "                    pieces = vocab.encode_as_pieces(line)\n",
        "                    if 0 < len(pieces):\n",
        "                        doc.append(pieces)\n",
        "                pbar.update(1)\n",
        "        if doc:\n",
        "            docs.append(doc)\n",
        "\n",
        "    for index in range(count):\n",
        "        output = out_file.format(index)\n",
        "        if os.path.isfile(output): continue\n",
        "\n",
        "        with open(output, \"w\") as out_f:\n",
        "            with tqdm_notebook(total=len(docs), desc=f\"Making\") as pbar:\n",
        "                for i, doc in enumerate(docs):\n",
        "                    instances = create_pretrain_instances(docs, i, doc, n_seq, mask_prob)\n",
        "                    for instance in instances:\n",
        "                        out_f.write(json.dumps(instance, ensure_ascii=False))\n",
        "                        out_f.write(\"\\n\")\n",
        "                    pbar.update(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPEwWM_qMoYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pretrain 파일 개수\n",
        "count = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36MJkxW_zd07",
        "colab_type": "code",
        "outputId": "c6ec5083-c052-4065-9a39-e75071086347",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "3f893cef3d474a15aab57e168205eedf",
            "10c886e2cf7c4eb5bca64b399098d168",
            "b4296d0ce29a4c7f8e575506c3835911",
            "26daeaba3b04460d87f5e9cfd8d85563",
            "e8124022674d485c9316ec64b2c456c9",
            "ddbba6da173642558aafa24f121bef2b",
            "b493c59c5e8d43649d2ed8484c909235",
            "69dffc7115af4e6eba4c1739db730db1"
          ]
        }
      },
      "source": [
        "in_file = f\"{data_dir}/kowiki.txt\"\n",
        "out_file = f\"{data_dir}/kowiki_t5\" + \"_{}.json\"\n",
        "n_seq = 256\n",
        "mask_prob = 0.15\n",
        "\n",
        "make_pretrain_data(vocab, in_file, out_file, count, n_seq, mask_prob)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f893cef3d474a15aab57e168205eedf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Loading', max=3724301, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgAxx2YImNOw",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Pretrain Data\n",
        "BERT Pretrain Data 입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8GPvntkmRlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain 데이터셋 \"\"\"\n",
        "class PretrainDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, vocab, infile):\n",
        "        self.vocab = vocab\n",
        "        self.labels = []\n",
        "        self.enc_inputs = []\n",
        "        self.dec_inputs = []\n",
        "\n",
        "        line_cnt = 0\n",
        "        with open(infile, \"r\") as f:\n",
        "            for line in f:\n",
        "                line_cnt += 1\n",
        "\n",
        "        with open(infile, \"r\") as f:\n",
        "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
        "                instance = json.loads(line)\n",
        "                enc_input = [vocab.piece_to_id(p) for p in instance[\"enc_input\"]]\n",
        "                dec_input = [vocab.piece_to_id(p) for p in instance[\"dec_input\"]]\n",
        "                self.labels.append(dec_input + [vocab.piece_to_id(\"[EOS]\")])\n",
        "                self.enc_inputs.append(enc_input)\n",
        "                self.dec_inputs.append([vocab.piece_to_id(\"[BOS]\")] + dec_input)\n",
        "    \n",
        "    def __len__(self):\n",
        "        assert len(self.labels) == len(self.enc_inputs)\n",
        "        assert len(self.labels) == len(self.dec_inputs)\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        return (torch.tensor(self.labels[item]),\n",
        "                torch.tensor(self.enc_inputs[item]),\n",
        "                torch.tensor(self.dec_inputs[item]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ONVNep2nM05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" pretrain data collate_fn \"\"\"\n",
        "def pretrin_collate_fn(inputs):\n",
        "    labels, enc_inputs, dec_inputs = list(zip(*inputs))\n",
        "\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-1)\n",
        "    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n",
        "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
        "\n",
        "    batch = [\n",
        "        labels,\n",
        "        enc_inputs,\n",
        "        dec_inputs\n",
        "    ]\n",
        "    return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzPPga8ZnQsq",
        "colab_type": "code",
        "outputId": "0f2de6db-b50d-47a5-d087-399aaeaf675d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\" pretrain 데이터 로더 \"\"\"\n",
        "batch_size = 128\n",
        "dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_t5_0.json\")\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/Data/transformer-evolution/kowiki_t5_0.json: 100%|██████████| 239325/239325 [00:46<00:00, 5133.59 lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO9hUtT6pgS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" 모델 epoch 학습 \"\"\"\n",
        "def train_epoch(config, epoch, model, criterion, optimizer, train_loader):\n",
        "    losses = []\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
        "        for i, value in enumerate(train_loader):\n",
        "            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(enc_inputs, dec_inputs)\n",
        "            logits = outputs[0]\n",
        "\n",
        "            loss = criterion(logits.view(-1, logits.size(2)), labels.view(-1))\n",
        "\n",
        "            loss_val = loss.item()\n",
        "            losses.append(loss_val)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
        "    return np.mean(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl7i2KUTqInp",
        "colab_type": "code",
        "outputId": "2b489b02-ae11-416c-9b37-949a23801723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(config)\n",
        "\n",
        "learning_rate = 5e-5\n",
        "n_epoch = 4"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_vocab': 8033, 'n_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KUHixRPqNpc",
        "colab_type": "code",
        "outputId": "efb516e5-ae2f-4097-f54c-a22a93c69e10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model = T5Pretrain(config)\n",
        "\n",
        "save_pretrain = f\"{data_dir}/save_t5_pretrain.pth\"\n",
        "best_epoch, best_loss = 0, 0\n",
        "if os.path.isfile(save_pretrain):\n",
        "    best_epoch, best_loss = model.t5.load(save_pretrain)\n",
        "    print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
        "    best_epoch += 1\n",
        "\n",
        "model.to(config.device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-1, reduction='mean')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "losses = []\n",
        "offset = best_epoch\n",
        "for step in range(n_epoch):\n",
        "    epoch = step + offset\n",
        "    if 0 < step and 1 < count:\n",
        "        del train_loader\n",
        "        dataset = PretrainDataSet(vocab, f\"{data_dir}/kowiki_t5_{epoch % count}.json\")\n",
        "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=pretrin_collate_fn)\n",
        "\n",
        "    loss = train_epoch(config, epoch, model, criterion, optimizer, train_loader)\n",
        "    losses.append(loss)\n",
        "    model.t5.save(epoch, loss, save_pretrain)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rTrain(8):   0%|          | 0/1870 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "load pretrain from: /content/drive/My Drive/Data/transformer-evolution/save_t5_pretrain.pth, epoch=7, loss=5.530668131935405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train(8): 100%|██████████| 1870/1870 [18:28<00:00,  1.79it/s, Loss: 5.402 (5.394)]\n",
            "Train(9): 100%|██████████| 1870/1870 [18:35<00:00,  1.78it/s, Loss: 5.173 (5.267)]\n",
            "Train(10): 100%|██████████| 1870/1870 [18:39<00:00,  1.79it/s, Loss: 5.129 (5.160)]\n",
            "Train(11): 100%|██████████| 1870/1870 [18:41<00:00,  1.80it/s, Loss: 5.007 (5.069)]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO7-KlvSr8mV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "92bfb975-1b50-494a-abb3-46b759ce3c8e"
      },
      "source": [
        "# data\n",
        "data = {\n",
        "    \"loss\": losses\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "display(df)\n",
        "\n",
        "# graph\n",
        "plt.figure(figsize=[12, 4])\n",
        "plt.plot(losses, label=\"loss\")\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.639366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.987684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.623163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.216493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.001551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.828925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5.672611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.394377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5.267102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5.159925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>5.069447</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss\n",
              "0   16.639366\n",
              "1    7.987684\n",
              "2    6.623163\n",
              "3    6.216493\n",
              "4    6.001551\n",
              "5    5.828925\n",
              "6    5.672611\n",
              "7    5.394377\n",
              "8    5.267102\n",
              "9    5.159925\n",
              "10   5.069447"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAEGCAYAAACeiKhrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAE/j/w2XxDq0+tgMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}